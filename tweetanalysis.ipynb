{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74654e9e-9733-4bd5-a545-d57d30f5f9bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426cbea6-ca8c-4ec6-83eb-e32bd5b25097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f140298-ab98-4d83-b896-ea1da105d12b",
   "metadata": {},
   "source": [
    "1st row is header info <br>\n",
    "Class labels: 1: positive, -1: negative, 0: neutral, 2: mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6db8d9-46f5-4b57-a78d-bb320717f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama = pd.read_excel('./training-Obama-Romney-tweets.xlsx', usecols=\"B:E\", sheet_name=\"Obama\")\n",
    "obama.drop(0, inplace=True)\n",
    "obama.rename(columns={\"Anootated tweet\": \"tweet\", \"Unnamed: 4\": \"class\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7babe6b-d7c0-44f8-b9cb-1c5d03036e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama.drop(obama.loc[obama[\"tweet\"].isna()].index, inplace=True)\n",
    "obama.drop(obama.loc[obama[\"class\"].isna()].index, inplace=True) \n",
    "obama.drop(obama.loc[obama[\"class\"].isin(['irrelevant', 'irrevelant'])].index, inplace=True) \n",
    "obama['class'] = obama['class'].astype(int)\n",
    "obama.drop_duplicates(inplace=True)\n",
    "obama = obama.drop(obama.loc[obama[\"class\"] == 2].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b227c9-c2e2-4013-8e9a-d003e8ab8caf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744d519-a8bd-4da7-885a-f87f889d54f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f3471-b691-4bbc-af3e-9d820be5b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama.loc[obama[\"class\"].isna()]\n",
    "set(obama[\"class\"].tolist())\n",
    "obama.loc[obama[\"class\"].isin(['irrelevant', 'irrevelant'])].count()\n",
    "obama.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ad8a1-d4f0-4c24-8afe-6e1f13aecff8",
   "metadata": {},
   "source": [
    "Since we need to only predict 1, 0, -1 classes, we can drop the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c548f2a1-984d-4d66-b3cd-af13350caba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama.drop(obama.loc[obama[\"tweet\"].isna()].index, inplace=True)\n",
    "obama.drop(obama.loc[obama[\"class\"].isna()].index, inplace=True) \n",
    "obama.drop(obama.loc[obama[\"class\"].isin(['irrelevant', 'irrevelant'])].index, inplace=True) \n",
    "obama['class'] = obama['class'].astype(int)\n",
    "obama.drop_duplicates(inplace=True)\n",
    "obama = obama.drop(obama.loc[obama[\"class\"] == 2].index) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68d879-9986-4dc9-9f44-34ba4d2156c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c879fdae-c635-4042-8250-e2ca1d15c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe7ebd-17d8-4485-abeb-cf2ed3913caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama.drop(columns=['date', 'time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e154298e-a853-433b-8599-f249fd305ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dec4ec7-bb47-4e5a-a3aa-82a3e9000c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(value):\n",
    "    try:\n",
    "        # Try parsing ISO 8601 format (e.g., \"10:28:53-05:00\")\n",
    "        return pd.to_datetime(value.strip(), format=\"%H:%M:%S%z\", errors='coerce').time()\n",
    "    except:\n",
    "        # If it fails, try parsing the alternative format (e.g., \"AM 11:9:13\")\n",
    "        try:\n",
    "            return pd.to_datetime(value.strip(), format=\"%p %I:%M:%S\", errors='coerce').time()\n",
    "        except:\n",
    "            return None  # Return None if parsing fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "427b7906-e9db-4d3f-8c48-95d5666bb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['parsed_time'] = obama['time'].apply(parse_time)\n",
    "obama = obama.dropna(subset=['parsed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9df4e2de-802a-489d-b769-28e4f00b53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(time_obj):\n",
    "    return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b92c5ea-0187-4458-b257-32afc1750a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7092/193614351.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obama['time_in_seconds'] = obama['parsed_time'].apply(time_to_seconds)\n"
     ]
    }
   ],
   "source": [
    "obama['time_in_seconds'] = obama['parsed_time'].apply(time_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2286770-cdd6-4481-82c4-d3b1a69bafd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>parsed_time</th>\n",
       "      <th>time_in_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "      <td>10:28:53</td>\n",
       "      <td>37733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-10 00:00:00</td>\n",
       "      <td>10:09:00-05:00</td>\n",
       "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>10:09:00</td>\n",
       "      <td>36540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "      <td>10:04:30</td>\n",
       "      <td>36270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:36-05:00</td>\n",
       "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>10:00:36</td>\n",
       "      <td>36036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>09:50:08</td>\n",
       "      <td>35408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:7:09</td>\n",
       "      <td>The Reason &lt;e&gt;Ann Romney&lt;/e&gt; And &lt;e&gt;Michelle ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:07:09</td>\n",
       "      <td>40029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:9:13</td>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt; Kenakan Cincin Syahadat Sejak SM...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:09:13</td>\n",
       "      <td>40153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:11:34</td>\n",
       "      <td>Bitches be like \"Obama&lt;3\" bitches just want &lt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:11:34</td>\n",
       "      <td>40294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:13:16</td>\n",
       "      <td>&lt;e&gt;president&lt;/e&gt; Barack &lt;e&gt;Obama&lt;/e&gt; and Repu...</td>\n",
       "      <td>2</td>\n",
       "      <td>11:13:16</td>\n",
       "      <td>40396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:13:59</td>\n",
       "      <td>#ThatsSoRude you trying to get into Obama's f...</td>\n",
       "      <td>2</td>\n",
       "      <td>11:13:59</td>\n",
       "      <td>40439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date            time  \\\n",
       "1     2012-10-16 00:00:00  10:28:53-05:00   \n",
       "2     2016-12-10 00:00:00  10:09:00-05:00   \n",
       "3     2012-10-16 00:00:00  10:04:30-05:00   \n",
       "4     2012-10-16 00:00:00  10:00:36-05:00   \n",
       "5     2012-10-16 00:00:00  09:50:08-05:00   \n",
       "...                   ...             ...   \n",
       "7194           10/17/2012      AM 11:7:09   \n",
       "7195           10/17/2012      AM 11:9:13   \n",
       "7196           10/17/2012     AM 11:11:34   \n",
       "7197           10/17/2012     AM 11:13:16   \n",
       "7198           10/17/2012     AM 11:13:59   \n",
       "\n",
       "                                                  tweet  class parsed_time  \\\n",
       "1     Kirkpatrick, who wore a baseball cap embroider...      0    10:28:53   \n",
       "2     Question: If <e>Romney</e> and <e>Obama</e> ha...      2    10:09:00   \n",
       "3     #<e>obama</e> debates that Cracker Ass Cracker...      1    10:04:30   \n",
       "4     RT @davewiner Slate: Blame <e>Obama</e> for fo...      2    10:00:36   \n",
       "5     @Hollivan @hereistheanswer  Youre missing the ...      0    09:50:08   \n",
       "...                                                 ...    ...         ...   \n",
       "7194   The Reason <e>Ann Romney</e> And <e>Michelle ...      0    11:07:09   \n",
       "7195   <e>Obama</e> Kenakan Cincin Syahadat Sejak SM...      0    11:09:13   \n",
       "7196   Bitches be like \"Obama<3\" bitches just want <...      0    11:11:34   \n",
       "7197   <e>president</e> Barack <e>Obama</e> and Repu...      2    11:13:16   \n",
       "7198   #ThatsSoRude you trying to get into Obama's f...      2    11:13:59   \n",
       "\n",
       "      time_in_seconds  \n",
       "1               37733  \n",
       "2               36540  \n",
       "3               36270  \n",
       "4               36036  \n",
       "5               35408  \n",
       "...               ...  \n",
       "7194            40029  \n",
       "7195            40153  \n",
       "7196            40294  \n",
       "7197            40396  \n",
       "7198            40439  \n",
       "\n",
       "[5755 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e31f5-c991-4678-9ab8-1b2ba04f4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(obama['time_in_seconds'], obama['class'], alpha=0.7)\n",
    "plt.title(\"Time vs Class Distribution\")\n",
    "plt.xlabel(\"Time (seconds since midnight)\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Format the x-axis to display time in HH:MM format\n",
    "plt.xticks(\n",
    "    ticks=range(0, 86401, 3600),  # Seconds in a day with hourly intervals\n",
    "    labels=[f\"{h:02d}:00\" for h in range(24)]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c195e-cc76-462a-82d6-152e41aaa9c6",
   "metadata": {},
   "source": [
    "No coorelation can be extracted from the time component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44808510-8531-4ff6-8a10-953a06fe8ce6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tweet column Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c439942-1284-4131-8830-3efe1ab89bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec46e212-b699-4b84-8321-edd6a7530ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.sub(r'<.*?>', '', text)\n",
    "    return clean\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "obama['tweet'] = obama['tweet'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "807adcd0-6c48-40bc-bdbf-0589c54260ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>parsed_time</th>\n",
       "      <th>time_in_seconds</th>\n",
       "      <th>processed</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "      <td>10:28:53</td>\n",
       "      <td>37733</td>\n",
       "      <td>[kirkpatrick, wore, baseball, cap, embroidered...</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#obama debates that Cracker Ass Cracker tonigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>10:04:30</td>\n",
       "      <td>36270</td>\n",
       "      <td>[e, obama, debates, cracker, ass, cracker, ton...</td>\n",
       "      <td>#obama debates that Cracker Ass Cracker tonigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>09:50:08</td>\n",
       "      <td>35408</td>\n",
       "      <td>[hollivan, hereistheanswer, youre, missing, po...</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:16-05:00</td>\n",
       "      <td>I was raised as a Democrat  left the party yea...</td>\n",
       "      <td>-1</td>\n",
       "      <td>10:00:16</td>\n",
       "      <td>36016</td>\n",
       "      <td>[raised, democrat, left, party, years, ago, 19...</td>\n",
       "      <td>I was raised as a Democrat  left the party yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:48:07-05:00</td>\n",
       "      <td>The Obama camp can't afford to lower expectati...</td>\n",
       "      <td>0</td>\n",
       "      <td>09:48:07</td>\n",
       "      <td>35287</td>\n",
       "      <td>[e, obama, camp, ca, afford, lower, expectatio...</td>\n",
       "      <td>The Obama camp can't afford to lower expectati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:2:29</td>\n",
       "      <td>except for women who work in the WH (they mak...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:02:29</td>\n",
       "      <td>39749</td>\n",
       "      <td>[except, women, work, wh, make, 18, less, hone...</td>\n",
       "      <td>except for women who work in the WH (they mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:6:19</td>\n",
       "      <td>20 Days to Election &amp; Selection.  Elect Lewis...</td>\n",
       "      <td>1</td>\n",
       "      <td>11:06:19</td>\n",
       "      <td>39979</td>\n",
       "      <td>[20, days, election, selection, elect, lewis, ...</td>\n",
       "      <td>20 Days to Election &amp; Selection.  Elect Lewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:7:09</td>\n",
       "      <td>The Reason Ann Romney And Michelle Obama Matc...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:07:09</td>\n",
       "      <td>40029</td>\n",
       "      <td>[reason, e, ann, romney, e, michelle, obama, m...</td>\n",
       "      <td>The Reason Ann Romney And Michelle Obama Matc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:9:13</td>\n",
       "      <td>Obama Kenakan Cincin Syahadat Sejak SMA? http...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:09:13</td>\n",
       "      <td>40153</td>\n",
       "      <td>[e, obama, kenakan, cincin, syahadat, sejak, s...</td>\n",
       "      <td>Obama Kenakan Cincin Syahadat Sejak SMA? http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>10/17/2012</td>\n",
       "      <td>AM 11:11:34</td>\n",
       "      <td>Bitches be like \"Obamafood stamps lmao _Ù÷â  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11:11:34</td>\n",
       "      <td>40294</td>\n",
       "      <td>[bitches, like, obama, 3, bitches, want, food,...</td>\n",
       "      <td>Bitches be like \"Obamafood stamps lmao _Ù÷â  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4497 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date            time  \\\n",
       "1     2012-10-16 00:00:00  10:28:53-05:00   \n",
       "3     2012-10-16 00:00:00  10:04:30-05:00   \n",
       "5     2012-10-16 00:00:00  09:50:08-05:00   \n",
       "7     2012-10-16 00:00:00  10:00:16-05:00   \n",
       "8     2012-10-16 00:00:00  09:48:07-05:00   \n",
       "...                   ...             ...   \n",
       "7191           10/17/2012      AM 11:2:29   \n",
       "7193           10/17/2012      AM 11:6:19   \n",
       "7194           10/17/2012      AM 11:7:09   \n",
       "7195           10/17/2012      AM 11:9:13   \n",
       "7196           10/17/2012     AM 11:11:34   \n",
       "\n",
       "                                                  tweet  class parsed_time  \\\n",
       "1     Kirkpatrick, who wore a baseball cap embroider...      0    10:28:53   \n",
       "3     #obama debates that Cracker Ass Cracker tonigh...      1    10:04:30   \n",
       "5     @Hollivan @hereistheanswer  Youre missing the ...      0    09:50:08   \n",
       "7     I was raised as a Democrat  left the party yea...     -1    10:00:16   \n",
       "8     The Obama camp can't afford to lower expectati...      0    09:48:07   \n",
       "...                                                 ...    ...         ...   \n",
       "7191   except for women who work in the WH (they mak...      0    11:02:29   \n",
       "7193   20 Days to Election & Selection.  Elect Lewis...      1    11:06:19   \n",
       "7194   The Reason Ann Romney And Michelle Obama Matc...      0    11:07:09   \n",
       "7195   Obama Kenakan Cincin Syahadat Sejak SMA? http...      0    11:09:13   \n",
       "7196   Bitches be like \"Obamafood stamps lmao _Ù÷â  ...      0    11:11:34   \n",
       "\n",
       "      time_in_seconds                                          processed  \\\n",
       "1               37733  [kirkpatrick, wore, baseball, cap, embroidered...   \n",
       "3               36270  [e, obama, debates, cracker, ass, cracker, ton...   \n",
       "5               35408  [hollivan, hereistheanswer, youre, missing, po...   \n",
       "7               36016  [raised, democrat, left, party, years, ago, 19...   \n",
       "8               35287  [e, obama, camp, ca, afford, lower, expectatio...   \n",
       "...               ...                                                ...   \n",
       "7191            39749  [except, women, work, wh, make, 18, less, hone...   \n",
       "7193            39979  [20, days, election, selection, elect, lewis, ...   \n",
       "7194            40029  [reason, e, ann, romney, e, michelle, obama, m...   \n",
       "7195            40153  [e, obama, kenakan, cincin, syahadat, sejak, s...   \n",
       "7196            40294  [bitches, like, obama, 3, bitches, want, food,...   \n",
       "\n",
       "                                          cleaned_tweet  \n",
       "1     Kirkpatrick, who wore a baseball cap embroider...  \n",
       "3     #obama debates that Cracker Ass Cracker tonigh...  \n",
       "5     @Hollivan @hereistheanswer  Youre missing the ...  \n",
       "7     I was raised as a Democrat  left the party yea...  \n",
       "8     The Obama camp can't afford to lower expectati...  \n",
       "...                                                 ...  \n",
       "7191   except for women who work in the WH (they mak...  \n",
       "7193   20 Days to Election & Selection.  Elect Lewis...  \n",
       "7194   The Reason Ann Romney And Michelle Obama Matc...  \n",
       "7195   Obama Kenakan Cincin Syahadat Sejak SMA? http...  \n",
       "7196   Bitches be like \"Obamafood stamps lmao _Ù÷â  ...  \n",
       "\n",
       "[4497 rows x 8 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6fe20-b46c-4265-80f9-d4d05e2e7306",
   "metadata": {},
   "source": [
    "Removing the html tags does not seem to impact the accuracy of the NBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abefdcc-8be1-4b03-92f1-9df4ed2fb415",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0b443e4-bc59-4a12-aee4-a92d44550d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_excel('sample-testdata.xlsx', usecols=\"B:E\", sheet_name=\"Obama\")\n",
    "test = pd.read_excel('./training-Obama-Romney-tweets.xlsx', usecols=\"B:E\", sheet_name=\"Romney\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49467795-16a1-4b4c-aada-e286bae70b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.drop(0, inplace=True)\n",
    "# test.rename(columns={\"Anootated tweet\": \"tweet\", \"Unnamed: 4\": \"class\"}, inplace=True)\n",
    "# test.drop(columns=['date', 'time'], inplace=True)\n",
    "# test.drop(test.loc[test[\"tweet\"].isna()].index, inplace=True)\n",
    "# test.drop(test.loc[test[\"class\"].isna()].index, inplace=True) \n",
    "# test.drop(test.loc[test[\"class\"].isin(['irrelevant', 'irrevelant'])].index, inplace=True) \n",
    "# test['class'] = test['class'].astype(int)\n",
    "# test.drop(test.loc[test[\"class\"].isin(['!!!!', 'IR'])].index, inplace=True) \n",
    "# test.drop_duplicates(inplace=True)\n",
    "test = test.drop(test.loc[test[\"class\"] == 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6df2d2f0-d4c1-4c1a-875a-57408c7681af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tweet'] = test['tweet'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388f001-bbde-4c23-9163-c078fe1e1068",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185356d-862f-416e-b71e-30d29a5f97a8",
   "metadata": {},
   "source": [
    "## NBC using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "12a3f872-5685-40c5-9443-853d06499814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.util import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b30743-33df-4076-9e26-ec1f897b086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e86c93b-ad6d-4dae-b8a8-8f18b885cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20a883e2-4fca-41fa-aa1d-13c7caaaaba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    words = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    return [word for word in words if word.isalnum() and word not in stop_words] \n",
    "\n",
    "def extract_features(words):\n",
    "    return {word: True for word in words}  # Map each word to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55286e53-5b6a-4638-afca-38fbb43e96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['processed'] = obama['tweet'].apply(preprocess)\n",
    "train_features = [\n",
    "    (extract_features(row['processed']), row['class'])\n",
    "    for _, row in obama.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a0f0ff1-27f9-47fa-86e0-26f56414cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['processed'] = test['tweet'].apply(preprocess)\n",
    "test_features = [\n",
    "    (extract_features(row['processed']), row['class'])\n",
    "    for _, row in test.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eda690eb-4a75-42f3-8b36-7fa6d70f6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4453900709219858\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy:\", accuracy(classifier, test_features))\n",
    "\n",
    "# Classify new tweet\n",
    "# new_tweet = \"This service makes me so happy!\"\n",
    "# processed_tweet = preprocess(new_tweet)\n",
    "# print(\"Prediction:\", classifier.classify(extract_features(processed_tweet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c117d1-4a50-4735-bf68-d88ffb4ef644",
   "metadata": {},
   "source": [
    "## NBC with NLTK using Lidstone smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c70a021-5818-4897-add0-149d37aaa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.util import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd061a7b-27f9-41bd-90b2-0dd5d93a97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "def extract_features(words):\n",
    "    return {word: True for word in words}\n",
    "\n",
    "def train_with_lidstone(train_data, lidstone_lambda=0.1):\n",
    "    # Function to return Lidstone probability distribution\n",
    "    def lidstone_pdist(freqdist, bins):\n",
    "        return LidstoneProbDist(freqdist, lidstone_lambda, bins)\n",
    "\n",
    "    return NaiveBayesClassifier.train(train_data, estimator=lidstone_pdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ac91c197-564c-46c7-acfd-1a9bd9fddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['processed'] = obama['tweet'].apply(preprocess)\n",
    "train_features = [\n",
    "    (extract_features(row['processed']), row['class'])\n",
    "    for _, row in obama.iterrows()\n",
    "]\n",
    "\n",
    "test['processed'] = test['tweet'].apply(preprocess)\n",
    "test_features = [\n",
    "    (extract_features(row['processed']), row['class'])\n",
    "    for _, row in test.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3663815-c40e-4572-8e27-491acc11fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train_with_lidstone(obama, lidstone_lambda=0.1)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy:\", accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccaa4c9-979c-404c-8a61-f9fd655d20bb",
   "metadata": {},
   "source": [
    "Above code did not work, trying NBC lidstone smoothing with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a1907eca-2909-45d2-857f-cd1c42e58c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb1cd404-1a3c-4d48-a6ae-23d1c8baa9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(obama['tweet'])  # Convert text to feature vectors\n",
    "y = obama['class']  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c60d823f-46d1-454c-8b9e-e51abb532af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b22e4914-5456-451e-aa33-646297d1196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1  # Lidstone smoothing equivalent\n",
    "classifier = MultinomialNB(alpha=alpha)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0edc5bd1-ddce-441c-b8c2-4a3af9208c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.58      0.58       416\n",
      "           0       0.56      0.42      0.48       501\n",
      "           1       0.55      0.72      0.63       433\n",
      "\n",
      "    accuracy                           0.57      1350\n",
      "   macro avg       0.57      0.57      0.56      1350\n",
      "weighted avg       0.57      0.57      0.56      1350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4956d9-637f-4927-afee-61cfcefb00ba",
   "metadata": {},
   "source": [
    "Trying different lidstone constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0ac37fba-81d3-4aea-992c-c628c2dc5dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.58      0.58       416\n",
      "           0       0.58      0.56      0.57       501\n",
      "           1       0.62      0.65      0.64       433\n",
      "\n",
      "    accuracy                           0.60      1350\n",
      "   macro avg       0.60      0.60      0.60      1350\n",
      "weighted avg       0.59      0.60      0.60      1350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.9 # Lidstone smoothing equivalent\n",
    "classifier = MultinomialNB(alpha=alpha)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
