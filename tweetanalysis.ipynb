{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7422b9-6e05-4593-bdde-5f1e623c9dd1",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71139896-4b3d-4159-9f4d-af64a737d17d",
   "metadata": {},
   "source": [
    "## STOP! Please read this before you execute any further cells,\n",
    "if you are running on a personal computer, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56c6a7-6ff6-44b7-adeb-70c088ebd625",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa9674-fbe8-4149-b452-62b00f4a57b1",
   "metadata": {},
   "source": [
    "if you are running on Google Colab, you already have everything installed except datasets,\n",
    "run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6156b9-4b78-4226-9635-931a5b397e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca67cc-fabe-403f-9117-4e8d8ac06a66",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5827587-f0ec-4102-86a2-fcc2070189bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for data cleaning\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# for test handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# transformers/ encoders\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# our classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for the roberta classifier using hugging face APIs and torch\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AdamW, get_scheduler, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9c584-3c70-4de9-a413-b3282ad8ee5b",
   "metadata": {},
   "source": [
    "# Read data and basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f918bf3-f76f-4feb-908d-d72b820aa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = [\"Obama\", \"Romney\"]\n",
    "df = {}\n",
    "for sheet in sheet_names:\n",
    "    # rename columns, drop useless columns, format data, remove duplicates\n",
    "    sh = pd.read_excel('./training-Obama-Romney-tweets.xlsx', usecols=\"D:E\", sheet_name=sheet)\n",
    "    sh.rename(columns={\"Anootated tweet\": \"tweet\", \"Unnamed: 4\": \"class\"}, inplace=True)\n",
    "    sh.drop(0, inplace=True)\n",
    "    sh.drop(sh.loc[sh[\"tweet\"].isna()].index, inplace=True)\n",
    "    sh['class'] = sh['class'].astype(str)\n",
    "    sh.drop(sh.loc[~sh[\"class\"].isin(['1', '0', '-1'])].index, inplace=True)\n",
    "    sh.drop_duplicates(inplace=True)\n",
    "    sh['class'] = sh['class'].astype(int)\n",
    "    sh['tweet'] = sh['tweet'].astype(str)\n",
    "    df[sheet] = sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f0aed-ba77-4116-b31d-cfa04965c750",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f028d8-3898-43af-a996-8446ecbc996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/debian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/debian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\S+')\n",
    "st = nltk.PorterStemmer()\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "\n",
    "# preprocessing lambda, to be used to run against a pandas dataframe, you can selectively turn on and off the respective cleaning tools\n",
    "def preprocessing(x,\n",
    "                  removeHtmlTags=True,\n",
    "                  removeUrlLinks=True,\n",
    "                  removeMentions=False,\n",
    "                  removeHashtags=False,\n",
    "                  removeNonWords=False,\n",
    "                  removeSpecialSymbols=False,\n",
    "                  removeSmallWords=0,\n",
    "                  removeStopWords=False,\n",
    "                  stemWords=False,\n",
    "                  lemmatizeWords=False):\n",
    "    if removeHtmlTags: x=re.sub(r'<[^>]+>', '', x) \n",
    "    if removeUrlLinks: x=re.sub(r'http\\S+', '', x)\n",
    "    if removeUrlLinks: x=re.sub(r'www\\S+', '', x)\n",
    "    if removeSpecialSymbols: x=re.sub(r'[@#]+', '', x)\n",
    "    if removeMentions: x=re.sub(r'@\\S+', '', x)\n",
    "    if removeHashtags: x=re.sub(r'#\\S+', '', x)\n",
    "    if removeNonWords: x=re.sub(r'\\W+', ' ', x)\n",
    "    if removeSmallWords != 0: x=' '.join([w for w in x.split() if len(w)>removeSmallWords])\n",
    "    if removeStopWords: x = \" \".join([word for word in str(x).split() if word not in stop_words])\n",
    "    x = tokenizer.tokenize(x)\n",
    "    if stemWords: x = [st.stem(word) for word in x]\n",
    "    if lemmatizeWords: x = [lm.lemmatize(word) for word in x]\n",
    "    return ' '.join(x)\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 removeHtmlTags=True,\n",
    "                 removeUrlLinks=True,\n",
    "                 removeMentions=False,\n",
    "                 removeHashtags=False,\n",
    "                 removeSpecialSymbols=False,\n",
    "                 removeNonWords=False,\n",
    "                 removeSmallWords=0,\n",
    "                 removeStopWords=False,\n",
    "                 stemWords=False,\n",
    "                 lemmatizeWords=False):\n",
    "        self.removeHtmlTags = removeHashtags\n",
    "        self.removeUrlLinks = removeUrlLinks\n",
    "        self.removeMentions = removeMentions\n",
    "        self.removeHashtags = removeHashtags\n",
    "        self.removeNonWords = removeNonWords\n",
    "        self.removeSmallWords = removeSmallWords\n",
    "        self.removeStopWords = removeStopWords\n",
    "        self.stemWords = stemWords\n",
    "        self.lemmatizeWords = lemmatizeWords\n",
    "        self.removeSpecialSymbols = removeSpecialSymbols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(preprocessing,\n",
    "                                args=(self.removeHtmlTags,\n",
    "                                self.removeUrlLinks,\n",
    "                                self.removeMentions,\n",
    "                                self.removeHashtags,\n",
    "                                self.removeNonWords,\n",
    "                                self.removeSpecialSymbols,\n",
    "                                self.removeSmallWords,\n",
    "                                self.removeStopWords,\n",
    "                                self.stemWords,\n",
    "                                self.lemmatizeWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc0839-497d-4e22-a4c6-d184a402b066",
   "metadata": {},
   "source": [
    "# Hugging Face Classifier Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a7001f-5cd4-40be-90b0-6519b9a52a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "class HuggingFacePreprocessor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(preprocess)\n",
    "\n",
    "class HuggingFaceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model_name, num_labels=3, epochs=3, batch_size=16, lr=5e-5, max_length=128):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.lr = lr\n",
    "        self.max_length = max_length\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.enc = LabelEncoder()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Tokenize the data\n",
    "        encodings = self.tokenizer(list(X), truncation=True, padding=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        y_labels = self.enc.fit_transform(y)\n",
    "        labels = torch.tensor(y_labels, dtype=torch.long)\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Set up optimizer and scheduler\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.lr)\n",
    "        num_training_steps = len(dataloader) * self.epochs\n",
    "        lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        # Training loop\n",
    "        progress_bar = tqdm(range(num_training_steps), desc=\"Training\")\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch in dataloader:\n",
    "                input_ids, attention_mask, labels = [x.to(self.device) for x in batch]\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Tokenize the data\n",
    "        encodings = self.tokenizer(list(X), truncation=True, padding=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"])\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                input_ids, attention_mask = [x.to(self.device) for x in batch]\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "        return self.enc.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1325b-53c2-4ad2-8e1d-5210ef1eb9db",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9389275-4a5a-4a96-b146-9da0ec267d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = {}, {}, {}, {}\n",
    "for name in sheet_names:\n",
    "    X_train[name], X_test[name], y_train[name], y_test[name] = train_test_split(\n",
    "        df[name][\"tweet\"],\n",
    "        df[name][\"class\"],\n",
    "        test_size=0.2,\n",
    "        random_state=46548694)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0cb5c-189a-4c81-b404-1419dbf7545e",
   "metadata": {},
   "source": [
    "# Model Pipeline and Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b83f2-9011-42fe-abed-39c4e24b4a77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e76190e-b46e-4333-95ec-15d8770a0533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.67      0.62       390\n",
      "           0       0.56      0.54      0.55       397\n",
      "           1       0.65      0.56      0.60       335\n",
      "\n",
      "    accuracy                           0.59      1122\n",
      "   macro avg       0.60      0.59      0.59      1122\n",
      "weighted avg       0.59      0.59      0.59      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.83      0.71       589\n",
      "           0       0.48      0.30      0.37       344\n",
      "           1       0.57      0.36      0.45       195\n",
      "\n",
      "    accuracy                           0.59      1128\n",
      "   macro avg       0.56      0.50      0.51      1128\n",
      "weighted avg       0.57      0.59      0.56      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logRes = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,2), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', LogisticRegression(random_state=5235253))\n",
    "])\n",
    "\n",
    "obama_pipeline = clone(logRes)\n",
    "romney_pipeline = clone(logRes)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b6782-beab-4f25-8ace-230ccd770483",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87335ef9-0f02-4d36-99d1-a2b77335ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.69      0.62       390\n",
      "           0       0.57      0.56      0.56       397\n",
      "           1       0.70      0.53      0.60       335\n",
      "\n",
      "    accuracy                           0.60      1122\n",
      "   macro avg       0.61      0.59      0.60      1122\n",
      "weighted avg       0.60      0.60      0.59      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.90      0.72       589\n",
      "           0       0.52      0.23      0.32       344\n",
      "           1       0.62      0.29      0.39       195\n",
      "\n",
      "    accuracy                           0.59      1128\n",
      "   macro avg       0.58      0.47      0.48      1128\n",
      "weighted avg       0.58      0.59      0.54      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,3), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', SVC(random_state=5235253))\n",
    "])\n",
    "\n",
    "obama_pipeline = clone(svc)\n",
    "romney_pipeline = clone(svc)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bb436-82da-4edd-974b-b467e1bdb0e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf416c5-e483-45d6-b4b5-759d44f6723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.75      0.63       390\n",
      "           0       0.57      0.53      0.55       397\n",
      "           1       0.75      0.50      0.60       335\n",
      "\n",
      "    accuracy                           0.60      1122\n",
      "   macro avg       0.62      0.59      0.59      1122\n",
      "weighted avg       0.62      0.60      0.59      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.96      0.71       589\n",
      "           0       0.64      0.15      0.25       344\n",
      "           1       0.60      0.14      0.23       195\n",
      "\n",
      "    accuracy                           0.57      1128\n",
      "   macro avg       0.60      0.42      0.40      1128\n",
      "weighted avg       0.59      0.57      0.49      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiNBC = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, removeMentions=True, stemWords=True, lemmatizeWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,5), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', MultinomialNB(alpha=2))\n",
    "])\n",
    "\n",
    "obama_pipeline = clone(multiNBC)\n",
    "romney_pipeline = clone(multiNBC)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c360c2b8-aa5c-4ff2-acb7-67db1775eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.61      0.61       390\n",
      "           0       0.54      0.61      0.57       397\n",
      "           1       0.66      0.57      0.61       335\n",
      "\n",
      "    accuracy                           0.60      1122\n",
      "   macro avg       0.60      0.60      0.60      1122\n",
      "weighted avg       0.60      0.60      0.60      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.63      0.65       589\n",
      "           0       0.41      0.44      0.42       344\n",
      "           1       0.46      0.49      0.48       195\n",
      "\n",
      "    accuracy                           0.55      1128\n",
      "   macro avg       0.51      0.52      0.51      1128\n",
      "weighted avg       0.55      0.55      0.55      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bernoulliNBC = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,4), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', BernoulliNB(alpha=1)) \n",
    "])\n",
    "\n",
    "obama_pipeline = clone(bernoulliNBC)\n",
    "romney_pipeline = clone(bernoulliNBC)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e73ab3-9614-4c4f-ac37-b801ef8c8817",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f090aacb-51d7-4623-a025-0a052a48e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.68      0.62       390\n",
      "           0       0.57      0.56      0.56       397\n",
      "           1       0.63      0.50      0.55       335\n",
      "\n",
      "    accuracy                           0.58      1122\n",
      "   macro avg       0.59      0.58      0.58      1122\n",
      "weighted avg       0.59      0.58      0.58      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.82      0.68       589\n",
      "           0       0.41      0.26      0.32       344\n",
      "           1       0.61      0.28      0.38       195\n",
      "\n",
      "    accuracy                           0.55      1128\n",
      "   macro avg       0.53      0.45      0.46      1128\n",
      "weighted avg       0.53      0.55      0.52      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomForests = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,4), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', RandomForestClassifier(random_state=5235253)) \n",
    "])\n",
    "\n",
    "obama_pipeline = clone(randomForests)\n",
    "romney_pipeline = clone(randomForests)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2d6390-209b-404a-b171-3bc5a3f068d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.67      0.63       390\n",
      "           0       0.56      0.59      0.57       397\n",
      "           1       0.68      0.52      0.59       335\n",
      "\n",
      "    accuracy                           0.60      1122\n",
      "   macro avg       0.61      0.60      0.60      1122\n",
      "weighted avg       0.61      0.60      0.60      1122\n",
      "\n",
      "Romney Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.83      0.69       589\n",
      "           0       0.44      0.25      0.32       344\n",
      "           1       0.58      0.32      0.42       195\n",
      "\n",
      "    accuracy                           0.56      1128\n",
      "   macro avg       0.54      0.47      0.48      1128\n",
      "weighted avg       0.54      0.56      0.53      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomForests = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor(removeHashtags=True, stemWords=True)), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,5), max_features= 2500, smooth_idf=True)), \n",
    "    ('classifier', ExtraTreesClassifier(random_state=5235253)) \n",
    "])\n",
    "\n",
    "obama_pipeline = clone(randomForests)\n",
    "romney_pipeline = clone(randomForests)\n",
    "\n",
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "y_pred = {}\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(\"Obama Classification Report\")\n",
    "print(classification_report(y_test[\"Obama\"], y_pred[\"Obama\"]))\n",
    "print(\"Romney Classification Report\")\n",
    "print(classification_report(y_test[\"Romney\"], y_pred[\"Romney\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa34586-cd80-4314-b1c9-1d4c28680dc0",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22390cda-766b-472d-991d-c837408e2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1f4bda8d894ccbb2f1ec28a29e75ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf34bf74a774412b228c86230685e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9117cc3c6862418ba66d1e98b16c56a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa271e880d6b4f239e1c7950475b9dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6429ba6d50e4e4c912eb4892724ea93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', HuggingFacePreprocessor()),\n",
    "    ('classifier', HuggingFaceClassifier(model_name=\"cardiffnlp/twitter-roberta-base-sentiment\", num_labels=3))\n",
    "])\n",
    "\n",
    "obama_pipeline = clone(pipeline)\n",
    "romney_pipeline = clone(pipeline)\n",
    "y_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cb17e-972d-44cb-8959-e8092626e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_pipeline.fit(X_train['Obama'], y_train['Obama'])\n",
    "\n",
    "y_pred['Obama'] = obama_pipeline.predict(X_test['Obama'])\n",
    "print(classification_report(y_test['Obama'], y_pred['Obama']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85e1ff-3178-42bd-b17f-f7b77b950e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "romney_pipeline.fit(X_train['Romney'], y_train['Romney'])\n",
    "\n",
    "y_pred['Romney'] = romney_pipeline.predict(X_test['Romney'])\n",
    "print(classification_report(y_test['Romney'], y_pred['Romney']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4c290-6355-4970-b2b5-88c844c27ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(obama_pipeline, \"roberta_obama_pipeline.pkl\")\n",
    "joblib.dump(romney_pipeline, \"roberta_romney_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf85f87-a950-4fff-aebe-b8daa371a665",
   "metadata": {},
   "source": [
    "# Running against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3590a36-bdfb-4532-85d9-22ab4ae0a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = {}\n",
    "for sheet in sheet_names:\n",
    "    # rename columns, drop useless columns, format data, remove duplicates\n",
    "    sh = pd.read_excel('./sample-testdata.xlsx', sheet_name=sheet, header=None, names=['#', 'tweet'])\n",
    "    test_df[sheet] = sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7a04b3-5a90-4f9d-9e20-d0ffa103d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior &lt;e&gt;Romney&lt;/e&gt; Advisor Claims &lt;e&gt;Obama&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                                              tweet\n",
       "0  1  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...\n",
       "1  2  Senior <e>Romney</e> Advisor Claims <e>Obama</...\n",
       "2  3  .@WardBrenda @shortwave8669 @allanbourdius you...\n",
       "3  4  <e>Mitt Romney</e> still doesn't <a>believe</a..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Romney']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eba8f08-0195-4519-8b3f-19e37746e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_obama_pipeline = joblib.load('roberta_obama_pipeline.pkl')\n",
    "roberta_romney_pipeline = joblib.load('roberta_romney_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b308426c-f7d3-4f7b-81ff-8ad8958c4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d4968af-8fc7-483e-8917-b58bf243fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y['Obama'] = roberta_obama_pipeline.predict(test_df['Romney']['tweet'])\n",
    "test_y['Romney'] = roberta_romney_pipeline.predict(test_df['Romney']['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff5e41f-979f-4055-bb39-d832535750a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Romney']['Class'] = test_y['Romney']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f4dd10d-211e-40d3-acf8-e24e0f84be85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior &lt;e&gt;Romney&lt;/e&gt; Advisor Claims &lt;e&gt;Obama&lt;/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                                              tweet  Class\n",
       "0  1  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...     -1\n",
       "1  2  Senior <e>Romney</e> Advisor Claims <e>Obama</...      1\n",
       "2  3  .@WardBrenda @shortwave8669 @allanbourdius you...     -1\n",
       "3  4  <e>Mitt Romney</e> still doesn't <a>believe</a...     -1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Romney']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27094b34-4aab-41c2-9167-4b36af98156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('output.xlsx') as writer: \n",
    "    test_df['Romney'].to_excel(writer, sheet_name='Romney', index=False, header=False)\n",
    "    # test_df['Obama'].to_excel(writer, sheet_name='Obama', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb01cbd-6be2-4fa8-9fde-8fc2d731912d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9ccbbf2d-486c-4d31-bd44-af9d4bfa8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()), \n",
    "    ('vectorizer', TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,2), max_features= 5000, smooth_idf=True)), \n",
    "    ('classifier', LinearSVC(random_state=5235253))\n",
    "])\n",
    "\n",
    "param_combos = [\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, removeMentions=True, stemWords=True, lemmatizeWords=True)], \n",
    "        'vectorizer': [CountVectorizer(token_pattern=r'\\S+', ngram_range=(1,1), strip_accents='unicode', max_features=5000)],\n",
    "        'classifier': [MultinomialNB(alpha=2.5)]\n",
    "    },\n",
    "    {\n",
    "    \t'preprocessor': [TextPreprocessor(removeHashtags=True, removeMentions=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,5), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [MultinomialNB(alpha=2)]\n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,5), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [ExtraTreesClassifier(random_state=5235253)]\n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,2), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [LogisticRegression(random_state=5235253)]\n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,4), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [RandomForestClassifier(random_state=5235253)] \n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,4), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [BernoulliNB(alpha=1)]\n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,3), max_features= 2500, smooth_idf=True)], \n",
    "    \t'classifier': [SVC(random_state=5235253)]\n",
    "    },\n",
    "    {\n",
    "        'preprocessor': [TextPreprocessor(removeHashtags=True, stemWords=True, lemmatizeWords=True)], \n",
    "    \t'vectorizer': [TfidfVectorizer(token_pattern=r'\\S+', ngram_range=(1,2), max_features= 5000, smooth_idf=True)], \n",
    "    \t'classifier': [LinearSVC(random_state=5235253)]\n",
    "    }\n",
    "]\n",
    "\n",
    "obama_pipeline = clone(pipeline)\n",
    "romney_pipeline = clone(pipeline)\n",
    "\n",
    "obama_grid_search = GridSearchCV(obama_pipeline, param_combos, cv=5, scoring='accuracy', verbose=2)\n",
    "romney_grid_search = GridSearchCV(romney_pipeline, param_combos, cv=5, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a36c23-fcc8-49f9-aad9-b1c14c921dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_grid_search.fit(X_train[\"Obama\"], y_train[\"Obama\"])\n",
    "y_pred = obama_grid_search.best_estimator_.predict(X_test[\"Obama\"])\n",
    "print(classification_report(y_test[\"Obama\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648dd24-56b1-4978-95f4-185344f63987",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = obama_grid_search.best_estimator_.predict(X_test[\"Obama\"])\n",
    "print(classification_report(y_test[\"Obama\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d16a1ed7-f411-445c-9c21-75f41444b4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[MultinomialNB(alpha=2.5), MultinomialNB(alpha=2),\n",
       "                   ExtraTreesClassifier(random_state=5235253),\n",
       "                   LogisticRegression(random_state=5235253),\n",
       "                   RandomForestClassifier(random_state=5235253),\n",
       "                   BernoulliNB(alpha=1), SVC(random_state=5235253),\n",
       "                   LinearSVC(random_state=5235253)],\n",
       "             mask=[False, False, False, False, False, False, False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_grid_search.cv_results_['param_classifier']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
